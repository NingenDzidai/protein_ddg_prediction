{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import pathlib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g:\\Работа\\BioCad\\мл_биоинф\\protein_ddg_prediction\\data\\skempi_v2_preprocessed.csv\n"
     ]
    }
   ],
   "source": [
    "path = pathlib.Path(os.getcwd())\n",
    "path = path.parent.absolute()\n",
    "path_data = os.path.join(path, 'data')\n",
    "path = os.path.join(path, 'data', 'skempi_v2_preprocessed.csv')\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed data\n",
    "df = pd.read_csv(path, sep = ';') \n",
    "\n",
    "# Separate features and target \n",
    "X = df.drop(columns='ddG_sign')\n",
    "y = df['ddG_sign']\n",
    "\n",
    "# Identify categorical features \n",
    "categorical_features = [\n",
    "    'Hold_out_type',\n",
    "    'Protein 1',\n",
    "    'Protein 2',\n",
    "    'iMutation_Location(s)_1',\n",
    "    'iMutation_Location(s)_2',\n",
    "    'orig_aa_1',\n",
    "    'chain_1',\n",
    "    'residue_num_1',\n",
    "    'mut_aa_1',\n",
    "    'orig_aa_2',\n",
    "    'chain_2',\n",
    "    'residue_num_2',\n",
    "    'mut_aa_2'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Create CatBoost pools\n",
    "train_pool = Pool(X_train, y_train, cat_features=categorical_features)\n",
    "val_pool = Pool(X_val, y_val, cat_features=categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.03, 0.05, 0.1],\n",
    "    'depth': [4, 6, 8]\n",
    "}\n",
    "\n",
    "# Initialize best parameters tracking\n",
    "best_params = None\n",
    "best_f1 = 0\n",
    "results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing lr=0.03, depth=4\n",
      "lr=0.03, depth=4 | Mean F1: 0.7903 ± 0.0035\n",
      "\n",
      "Testing lr=0.03, depth=6\n",
      "lr=0.03, depth=6 | Mean F1: 0.7948 ± 0.0060\n",
      "\n",
      "Testing lr=0.03, depth=8\n",
      "lr=0.03, depth=8 | Mean F1: 0.7948 ± 0.0049\n",
      "\n",
      "Testing lr=0.05, depth=4\n",
      "lr=0.05, depth=4 | Mean F1: 0.7949 ± 0.0075\n",
      "\n",
      "Testing lr=0.05, depth=6\n",
      "lr=0.05, depth=6 | Mean F1: 0.7960 ± 0.0076\n",
      "\n",
      "Testing lr=0.05, depth=8\n",
      "lr=0.05, depth=8 | Mean F1: 0.7998 ± 0.0085\n",
      "\n",
      "Testing lr=0.1, depth=4\n",
      "lr=0.1, depth=4 | Mean F1: 0.7996 ± 0.0027\n",
      "\n",
      "Testing lr=0.1, depth=6\n",
      "lr=0.1, depth=6 | Mean F1: 0.7980 ± 0.0127\n",
      "\n",
      "Testing lr=0.1, depth=8\n",
      "lr=0.1, depth=8 | Mean F1: 0.8014 ± 0.0123\n"
     ]
    }
   ],
   "source": [
    "# Grid search with cross-validation\n",
    "for lr in param_grid['learning_rate']:\n",
    "    for depth in param_grid['depth']:\n",
    "        print(f\"\\nTesting lr={lr}, depth={depth}\")\n",
    "        \n",
    "        cv_f1_scores = []\n",
    "        kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "            # Split data\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            # Create CatBoost pools\n",
    "            train_pool = Pool(X_train, y_train, cat_features=categorical_features)\n",
    "            val_pool = Pool(X_val, y_val, cat_features=categorical_features)\n",
    "            \n",
    "            # Initialize model with current parameters\n",
    "            model = CatBoostClassifier(\n",
    "                iterations=1000,\n",
    "                learning_rate=lr,\n",
    "                depth=depth,\n",
    "                loss_function='MultiClass',\n",
    "                eval_metric='TotalF1',\n",
    "                cat_features=categorical_features,\n",
    "                early_stopping_rounds=50,\n",
    "                verbose=0  # Set to 100 for detailed training logs\n",
    "            )\n",
    "            \n",
    "            # Train\n",
    "            model.fit(train_pool, eval_set=val_pool, use_best_model=True)\n",
    "            \n",
    "            # Evaluate\n",
    "            y_pred = model.predict(X_val)\n",
    "            fold_f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "            cv_f1_scores.append(fold_f1)\n",
    "        \n",
    "        # Calculate mean F1 across folds\n",
    "        mean_f1 = np.mean(cv_f1_scores)\n",
    "        std_f1 = np.std(cv_f1_scores)\n",
    "        results.append((lr, depth, mean_f1, std_f1))\n",
    "        \n",
    "        print(f\"lr={lr}, depth={depth} | Mean F1: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "        \n",
    "        # Update best parameters\n",
    "        if mean_f1 > best_f1:\n",
    "            best_f1 = mean_f1\n",
    "            best_params = {'learning_rate': lr, 'depth': depth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean CV F1: 0.8020 ± 0.0114\n",
      "\n",
      "=== Grid Search Results ===\n",
      "lr=0.03, depth=4: F1 = 0.7903 ± 0.0035\n",
      "lr=0.03, depth=6: F1 = 0.7948 ± 0.0060\n",
      "lr=0.03, depth=8: F1 = 0.7948 ± 0.0049\n",
      "lr=0.05, depth=4: F1 = 0.7949 ± 0.0075\n",
      "lr=0.05, depth=6: F1 = 0.7960 ± 0.0076\n",
      "lr=0.05, depth=8: F1 = 0.7998 ± 0.0085\n",
      "lr=0.1, depth=4: F1 = 0.7996 ± 0.0027\n",
      "lr=0.1, depth=6: F1 = 0.7980 ± 0.0127\n",
      "lr=0.1, depth=8: F1 = 0.8014 ± 0.0123\n",
      "\n",
      "Best parameters: {'learning_rate': 0.1, 'depth': 8} (F1 = 0.8014)\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation\n",
    "print(f\"\\nMean CV F1: {np.mean(cv_f1_scores):.4f} ± {np.std(cv_f1_scores):.4f}\")\n",
    "print(\"\\n=== Grid Search Results ===\")\n",
    "for lr, depth, mean_f1, std_f1 in results:\n",
    "    print(f\"lr={lr}, depth={depth}: F1 = {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "print(f\"\\nBest parameters: {best_params} (F1 = {best_f1:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dba8683514341dc9ff51a495b94b558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6663942\ttotal: 41ms\tremaining: 41s\n",
      "100:\tlearn: 0.8321602\ttotal: 9.21s\tremaining: 1m 21s\n",
      "200:\tlearn: 0.8825675\ttotal: 19.5s\tremaining: 1m 17s\n",
      "300:\tlearn: 0.9180494\ttotal: 29.5s\tremaining: 1m 8s\n",
      "400:\tlearn: 0.9441455\ttotal: 38.9s\tremaining: 58.1s\n",
      "500:\tlearn: 0.9606743\ttotal: 49.4s\tremaining: 49.2s\n",
      "600:\tlearn: 0.9728798\ttotal: 1m\tremaining: 40s\n",
      "700:\tlearn: 0.9841490\ttotal: 1m 11s\tremaining: 30.7s\n",
      "800:\tlearn: 0.9907103\ttotal: 1m 22s\tremaining: 20.5s\n",
      "900:\tlearn: 0.9946149\ttotal: 1m 33s\tremaining: 10.3s\n",
      "999:\tlearn: 0.9967731\ttotal: 1m 44s\tremaining: 0us\n",
      "\n",
      "=== Final Test Evaluation ===\n",
      "Test F1 Score: 0.7942\n"
     ]
    }
   ],
   "source": [
    "# Train final model with best parameters\n",
    "final_model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    depth=best_params['depth'],\n",
    "    loss_function='MultiClass',\n",
    "    eval_metric='TotalF1',\n",
    "    cat_features=categorical_features,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "# First split: 80% train (for grid search), 20% final test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "final_model.fit(\n",
    "    Pool(X_temp, y_temp, cat_features=categorical_features),\n",
    "    plot=True\n",
    ")\n",
    "\n",
    "# Evaluate on hold-out test set\n",
    "test_pool = Pool(X_test, y_test, cat_features=categorical_features)\n",
    "y_pred = final_model.predict(X_test)\n",
    "test_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"\\n=== Final Test Evaluation ===\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hold_out_type: 5.88\n",
      "Protein 1: 13.74\n",
      "Protein 2: 8.70\n",
      "iMutation_Location(s)_1: 13.86\n",
      "iMutation_Location(s)_2: 2.04\n",
      "orig_aa_1: 17.18\n",
      "chain_1: 7.52\n",
      "residue_num_1: 15.26\n",
      "mut_aa_1: 11.22\n",
      "orig_aa_2: 1.00\n",
      "chain_2: 1.11\n",
      "residue_num_2: 0.64\n",
      "mut_aa_2: 1.87\n"
     ]
    }
   ],
   "source": [
    "# Feature importance\n",
    "feature_importances = final_model.get_feature_importance()\n",
    "for feature, importance in zip(X.columns, feature_importances):\n",
    "    print(f\"{feature}: {importance:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.save_model('ddG_sign_model.cbm')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
